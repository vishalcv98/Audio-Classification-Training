{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWz9N6afaI3e"
      },
      "outputs": [],
      "source": [
        "import  sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from src.audio.exception import CustomException\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from src.audio.constants import *\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n"
      ],
      "metadata": {
        "id": "pOGErdC6aZJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n"
      ],
      "metadata": {
        "id": "ccvo7W3vafuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def my_fit_method(epochs, lr, model, train_data_loader, val_loader, opt_func=torch.optim.SGD,grad_clip=GRAD_CLIP):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr,weight_decay=WEIGHT_DECAY)\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, epochs=epochs,\n",
        "                                                steps_per_epoch=len(train_data_loader))\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "\n",
        "        for batch in train_data_loader:\n",
        "\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record & update learning rate\n",
        "            sched.step()\n",
        "\n",
        "        # Validation Phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history, result\n"
      ],
      "metadata": {
        "id": "VLPsmSCmaimO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def predict_image(img, model, device, num_classes):\n",
        "    # Convert to a batch of 1\n",
        "    ximg = to_device(img.unsqueeze(0), device)\n",
        "    yimg = model(ximg)\n",
        "    ## Picking the image with highest probability\n",
        "    prob, preds  = torch.max(yimg, dim=1)\n",
        "    # Getting the class label\n",
        "    num_classes = ['cat', 'dog']\n",
        "    return num_classes[preds[0].item()]"
      ],
      "metadata": {
        "id": "lH3niyIOaki4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}