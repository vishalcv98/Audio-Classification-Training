{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0939ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.audio.constants import *\n",
    "from src.audio.logger import logging\n",
    "from src.audio.exception import CustomException\n",
    "from src.audio.entity.config_entity import *\n",
    "from src.audio.entity.artifact_entity import *\n",
    "\n",
    "# Suppress PIL debug logs\n",
    "logging.getLogger('PIL').setLevel(logging.WARNING)\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, data_transformation_config: DataTransformationConfig,\n",
    "                 data_ingestion_artifact: DataIngestionArtifacts) -> None:\n",
    "        try:\n",
    "            self.data_transformation_config = data_transformation_config\n",
    "            self.data_ingestion_artifact = data_ingestion_artifact\n",
    "            # Set device for GPU or CPU\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            logging.info(f\"Using device: {self.device}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def load_audio_files(self, path: str, label: str):\n",
    "        try:\n",
    "            dataset = []\n",
    "            walker = sorted(str(p) for p in Path(path).glob('*.wav'))\n",
    "            if not walker:\n",
    "                logging.warning(f\"No .wav files found in {path}\")\n",
    "                return dataset\n",
    "            for i, file_path in enumerate(walker):\n",
    "                path, filename = os.path.split(file_path)\n",
    "                speaker, _ = os.path.splitext(filename)\n",
    "                try:\n",
    "                    speaker_id, utterance_number = speaker.split(\"_nohash_\")\n",
    "                    utterance_number = int(utterance_number)\n",
    "                except ValueError:\n",
    "                    logging.warning(f\"Invalid filename format: {filename}. Skipping.\")\n",
    "                    continue\n",
    "                # Load audio\n",
    "                waveform, sample_rate = torchaudio.load(file_path)\n",
    "                dataset.append([waveform, sample_rate, label, speaker_id, utterance_number])\n",
    "            return dataset\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def create_spectrogram_images(self, dataloader, label_dir, is_test=False):\n",
    "        try:\n",
    "            # Set directory based on whether it's test or train data\n",
    "            base_dir = self.data_transformation_config.test_dir if is_test else self.data_transformation_config.images_dir\n",
    "            directory = os.path.join(base_dir, label_dir)\n",
    "            \n",
    "            if os.path.isdir(directory):\n",
    "                logging.info(f\"Spectrogram directory exists for {label_dir}: {directory}\")\n",
    "            else:\n",
    "                os.makedirs(directory, mode=0o777, exist_ok=True)\n",
    "                logging.info(f\"Created spectrogram directory: {directory}\")\n",
    "                \n",
    "            spectrogram_count = 0\n",
    "            for i, data in enumerate(dataloader):\n",
    "                waveform = data[0].to(self.device)  # Move to GPU\n",
    "                sample_rate = data[1]\n",
    "                label = data[2]\n",
    "                ID = data[3]\n",
    "\n",
    "                # Create transformed waveforms\n",
    "                spectrogram_transform = torchaudio.transforms.Spectrogram(\n",
    "                    n_fft=400, win_length=None, hop_length=None, window_fn=torch.hann_window\n",
    "                ).to(self.device)\n",
    "                spectrogram_tensor = spectrogram_transform(waveform)\n",
    "                \n",
    "                # Convert to log scale and handle NaN/inf\n",
    "                spectrogram_data = spectrogram_tensor[0].log2()\n",
    "                spectrogram_data = torch.where(\n",
    "                    torch.isfinite(spectrogram_data),\n",
    "                    spectrogram_data,\n",
    "                    torch.tensor(0.0, device=self.device)\n",
    "                )\n",
    "                path_to_save_img = os.path.join(directory, f\"spec_img{i}.png\")\n",
    "                print(spectrogram_data)\n",
    "                plt.imsave(path_to_save_img, spectrogram_data[0, :, :].cpu().numpy(), cmap='viridis')\n",
    "               \n",
    "                spectrogram_count += 1\n",
    "            logging.info(f\"Saved spectrogram: {path_to_save_img}\")\n",
    "            \n",
    "            if spectrogram_count == 0:\n",
    "                logging.warning(f\"No spectrogram images generated for {label_dir} in {base_dir}\")\n",
    "            else:\n",
    "                logging.info(f\"Generated {spectrogram_count} spectrogram images for {label_dir} in {base_dir}\")\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def initiate_data_transformation(self) -> DataTransformationArtifacts:\n",
    "        try:\n",
    "            logging.info(\"Initiating the data transformation component...\")\n",
    "            # Define folder paths for dog and cat\n",
    "            dog_folder_path = os.path.join(self.data_ingestion_artifact.data_folder_path, 'data', 'dog', '00f0204f_nohash_0.wav')\n",
    "            cat_folder_path = os.path.join(self.data_ingestion_artifact.data_folder_path, 'data', 'cat', '00b01445_nohash_0.wav')\n",
    "\n",
    "            # Verify folder existence\n",
    "            logging.info(f\"Dog folder exists: {os.path.exists(dog_folder_path)} ({dog_folder_path})\")\n",
    "            logging.info(f\"Cat folder exists: {os.path.exists(cat_folder_path)} ({cat_folder_path})\")\n",
    "\n",
    "            # Log directory paths for debugging\n",
    "            logging.info(f\"Training images directory: {self.data_transformation_config.images_dir}\")\n",
    "            logging.info(f\"Test images directory: {self.data_transformation_config.test_dir}\")\n",
    "\n",
    "            # Load datasets\n",
    "            dog_dataset = self.load_audio_files(dog_folder_path[:-22], 'dog')\n",
    "            cat_dataset = self.load_audio_files(cat_folder_path[:-22], 'cat')\n",
    "            logging.info(f'Length of dog dataset: {len(dog_dataset)}')\n",
    "            logging.info(f'Length of cat dataset: {len(cat_dataset)}')\n",
    "\n",
    "            if len(dog_dataset) == 0 or len(cat_dataset) == 0:\n",
    "                raise CustomException(\"No audio files found in dog or cat folders. Check the unzipped data structure.\", sys)\n",
    "\n",
    "            # Define test split ratio (20% for testing)\n",
    "            test_split_ratio = 0.3\n",
    "            num_test_dog = max(1, int(len(dog_dataset) * test_split_ratio))\n",
    "            num_test_cat = max(1, int(len(cat_dataset) * test_split_ratio))\n",
    "            logging.info(num_test_dog,num_test_cat)\n",
    "            #num_test_cat=num_test_cat[0]\n",
    "\n",
    "            # Split into train and test datasets\n",
    "            train_dog = dog_dataset[:-num_test_dog]\n",
    "            test_dog = dog_dataset[-num_test_dog:]\n",
    "            train_cat = cat_dataset[:-num_test_cat]\n",
    "            test_cat = cat_dataset[-num_test_cat:]\n",
    "\n",
    "            logging.info(f'Length of dog training dataset: {len(train_dog)}')\n",
    "            logging.info(f'Length of dog test dataset: {len(test_dog)}')\n",
    "            logging.info(f'Length of cat training dataset: {len(train_cat)}')\n",
    "            logging.info(f'Length of cat test dataset: {len(test_cat)}')\n",
    "\n",
    "            if len(test_dog) == 0 or len(test_cat) == 0:\n",
    "                raise CustomException(\"Test datasets are empty. Increase dataset size or adjust test_split_ratio.\", sys)\n",
    "\n",
    "            # Create DataLoaders with dynamic pin_memory\n",
    "            trainloader_dog = torch.utils.data.DataLoader(\n",
    "                train_dog, batch_size=1, shuffle=SHUFFLE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY\n",
    "            )\n",
    "            trainloader_cat = torch.utils.data.DataLoader(\n",
    "                train_cat, batch_size=1, shuffle=SHUFFLE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY\n",
    "            )\n",
    "            testloader_dog = torch.utils.data.DataLoader(\n",
    "                test_dog, batch_size=1, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY\n",
    "            )\n",
    "            testloader_cat = torch.utils.data.DataLoader(\n",
    "                test_cat, batch_size=1, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY\n",
    "            )\n",
    "\n",
    "            # Generate spectrogram images for train data\n",
    "            self.create_spectrogram_images(trainloader_dog, 'dog', is_test=False)\n",
    "            self.create_spectrogram_images(trainloader_cat, 'cat', is_test=False)\n",
    "\n",
    "            # Generate spectrogram images for test data\n",
    "            self.create_spectrogram_images(testloader_dog, 'dog', is_test=True)\n",
    "            self.create_spectrogram_images(testloader_cat, 'cat', is_test=True)\n",
    "\n",
    "            data_transformation_artifact = DataTransformationArtifacts(\n",
    "                images_folder_path=self.data_transformation_config.images_dir,\n",
    "                test_folder_path=self.data_transformation_config.test_dir\n",
    "            )\n",
    "            logging.info('Data transformation completed successfully.')\n",
    "            return data_transformation_artifact\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1b577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2031 files for label 'cat' from C:\\Users\\Vijay\\Audio-Classification\\artifacts\\data_ingestion\\unzip\\data\\cat\n",
      "Loaded 2128 files for label 'dog' from C:\\Users\\Vijay\\Audio-Classification\\artifacts\\data_ingestion\\unzip\\data\\dog\n"
     ]
    }
   ],
   "source": [
    "config = DataIngestionConfig()\n",
    "data_root = os.path.join(config.unzip_data_dir, \"data\")\n",
    "data_ingestion_artifact = DataIngestionArtifacts(data_folder_path=data_root)\n",
    "\n",
    "# Initialize the transformer\n",
    "transformer = DataTransformation(DataTransformationConfig, data_ingestion_artifact)\n",
    "\n",
    "# Loop through each label folder and load audio files\n",
    "for label in os.listdir(data_root):\n",
    "    label_path = os.path.join(data_root, label)\n",
    "    if os.path.isdir(label_path):\n",
    "        dataset = transformer.load_audio_files(label_path, label)\n",
    "        print(f\"Loaded {len(dataset)} files for label '{label}' from {label_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff1c94a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -2.7511,  -1.6723,  -1.5376,  ...,  -0.9409,  -0.6592,  -0.4613],\n",
      "        [ -4.8560,  -3.3070,  -3.7345,  ...,  -3.0781,  -2.9233,  -2.4961],\n",
      "        [-13.6548,  -8.6257,  -8.3919,  ...,  -8.0502,  -8.3797, -10.1240],\n",
      "        ...,\n",
      "        [-20.7285, -28.2786, -23.9475,  ..., -26.2888, -25.7873, -29.8650],\n",
      "        [-20.3315, -27.1780, -24.4559,  ..., -26.1126, -27.6021, -27.8082],\n",
      "        [-20.1701, -26.7114, -30.3692,  ..., -28.8527, -27.2926, -26.4373]])\n"
     ]
    },
    {
     "ename": "CustomException",
     "evalue": "Error occurred python script name [2963824229.py] line number [86] error message [too many indices for tensor of dimension 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 86\u001b[0m, in \u001b[0;36mDataTransformation.create_spectrogram_images\u001b[1;34m(self, dataloader, label_dir, is_test)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(spectrogram_data)\n\u001b[1;32m---> 86\u001b[0m plt\u001b[38;5;241m.\u001b[39mimsave(path_to_save_img, \u001b[43mspectrogram_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     88\u001b[0m spectrogram_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m dataset \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mload_audio_files(label_path, label)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Run create_spectrogram_images for this label\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_spectrogram_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 96\u001b[0m, in \u001b[0;36mDataTransformation.create_spectrogram_images\u001b[1;34m(self, dataloader, label_dir, is_test)\u001b[0m\n\u001b[0;32m     94\u001b[0m         logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspectrogram_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m spectrogram images for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CustomException(e, sys)\n",
      "\u001b[1;31mCustomException\u001b[0m: Error occurred python script name [2963824229.py] line number [86] error message [too many indices for tensor of dimension 2]"
     ]
    }
   ],
   "source": [
    "config = DataIngestionConfig()\n",
    "data_root = os.path.join(config.unzip_data_dir, \"data\")\n",
    "data_ingestion_artifact = DataIngestionArtifacts(data_folder_path=data_root)\n",
    "\n",
    "# Initialize the transformer\n",
    "transformer = DataTransformation(DataTransformationConfig, data_ingestion_artifact)\n",
    "\n",
    "# Choose a label to process (e.g., the first label folder)\n",
    "label = os.listdir(data_root)[0]  # or set label = \"yes\" or any label you want\n",
    "label_path = os.path.join(data_root, label)\n",
    "\n",
    "# Load audio files for this label\n",
    "dataset = transformer.load_audio_files(label_path, label)\n",
    "\n",
    "# Run create_spectrogram_images for this label\n",
    "transformer.create_spectrogram_images(dataset, label_dir=label, is_test=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
