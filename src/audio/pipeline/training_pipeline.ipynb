{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from src.audio.components.data_ingestion import DataIngestion\n",
        "from src.audio.components.data_transformation import DataTransformation\n",
        "from src.audio.components.model_training import ModelTraining\n",
        "from src.audio.components.mode_pusher import ModelPusher\n",
        "from src.audio.components.model_evaluation import ModelEvaluation\n",
        "from src.audio.logger import logging\n",
        "from src.audio.exception import CustomException\n",
        "from src.audio.entity.config_entity import *\n",
        "from src.audio.entity.artifact_entity import *\n"
      ],
      "metadata": {
        "id": "LUzPulWKbwyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TrainingPipeline:\n",
        "    def __init__(self):\n",
        "        self.data_ingestion_config = DataIngestionConfig()\n",
        "        self.data_transformation_config = DataTransformationConfig()\n",
        "        self.model_trainer_config = ModelTrainerConfig()\n",
        "        self.model_evaluation_config = ModelEvaluationConfig()\n",
        "\n",
        "    def start_data_ingestion(self) -> DataIngestionArtifacts:\n",
        "        logging.info(\"Starting data ingestion in training pipeline\")\n",
        "        try:\n",
        "            data_ingestion = DataIngestion(data_ingestion_config=self.data_ingestion_config)\n",
        "            data_ingestion_artifacts = data_ingestion.initiate_data_ingestion()\n",
        "            logging.info(\"Data ingestion step completed successfully in train pipeline\")\n",
        "            return data_ingestion_artifacts\n",
        "        except Exception as e:\n",
        "            raise CustomException(e, sys)\n",
        "\n",
        "    def start_data_transformation(self, data_ingestion_artifacts: DataIngestionArtifacts) -> DataTransformationArtifacts:\n",
        "        logging.info(\"Starting data preprocessing in training pipeline\")\n",
        "        try:\n",
        "            data_transformation = DataTransformation(\n",
        "                data_transformation_config=self.data_transformation_config,\n",
        "                data_ingestion_artifact=data_ingestion_artifacts\n",
        "            )\n",
        "            data_preprocessing_artifacts = data_transformation.initiate_data_transformation()\n",
        "            logging.info(\"Data preprocessing step completed successfully in train pipeline\")\n",
        "            return data_preprocessing_artifacts\n",
        "        except Exception as e:\n",
        "            raise CustomException(e, sys)\n",
        "\n",
        "    def start_model_trainer(self, data_transformation_artifact: DataTransformationArtifacts) -> ModelTrainerArtifacts:\n",
        "        try:\n",
        "            logging.info(\"Entered the start_model_trainer method of TrainPipeline class\")\n",
        "            model_trainer = ModelTraining(\n",
        "                data_transformation_artifact=data_transformation_artifact,\n",
        "                model_trainer_config=self.model_trainer_config\n",
        "            )\n",
        "            model_trainer_artifact = model_trainer.initiate_model_trainer()\n",
        "            logging.info(\"Exited the start_model_trainer method of TrainPipeline class\")\n",
        "            return model_trainer_artifact\n",
        "        except Exception as e:\n",
        "            raise CustomException(e, sys)\n",
        "\n",
        "    def start_model_evaluation(self, data_transformation_artifact: DataTransformationArtifacts, model_trainer_artifacts: ModelTrainerArtifacts) -> ModelEvaluationArtifacts:\n",
        "        logging.info(\"Starting model evaluation in training pipeline\")\n",
        "        try:\n",
        "            model_evaluation = ModelEvaluation(\n",
        "                self.model_evaluation_config,\n",
        "                data_transformation_artifact,\n",
        "                model_trainer_artifacts\n",
        "            )\n",
        "            logging.info(\"Evaluating current trained model\")\n",
        "            model_evaluation_artifacts = model_evaluation.initiate_model_evaluation()\n",
        "            logging.info(f\"Model evaluation artifacts: is_model_accepted={model_evaluation_artifacts.is_model_accepted}, \"\n",
        "                        f\"s3_model_loss={model_evaluation_artifacts.s3_model_loss}, \"\n",
        "                        f\"trained_model_loss={model_trainer_artifacts.result['val_loss']}, \"\n",
        "                        f\"base_loss={BASE_LOSS}\")\n",
        "            logging.info(\"Model evaluation step completed successfully in train pipeline\")\n",
        "            return model_evaluation_artifacts\n",
        "        except Exception as e:\n",
        "            raise CustomException(e, sys)\n",
        "\n",
        "    def start_model_pusher(self, model_evaluation_artifacts: ModelEvaluationArtifacts) -> ModelPusherArtifacts:\n",
        "        logging.info(\"Starting model pusher in training pipeline\")\n",
        "        try:\n",
        "            # Validate model_evaluation_artifacts\n",
        "            required_attrs = ['is_model_accepted', 'trained_model_path', 's3_model_path', 's3_model_loss']\n",
        "            missing_attrs = [attr for attr in required_attrs if not hasattr(model_evaluation_artifacts, attr)]\n",
        "            if missing_attrs:\n",
        "                raise ValueError(f\"ModelEvaluationArtifacts missing required attributes: {missing_attrs}\")\n",
        "\n",
        "            # Log evaluation details\n",
        "            logging.info(f\"Model pusher input: is_model_accepted={model_evaluation_artifacts.is_model_accepted}, \"\n",
        "                        f\"trained_model_path={model_evaluation_artifacts.trained_model_path}, \"\n",
        "                        f\"s3_model_path={model_evaluation_artifacts.s3_model_path}, \"\n",
        "                        f\"s3_model_loss={model_evaluation_artifacts.s3_model_loss}\")\n",
        "\n",
        "            model_pusher = ModelPusher(model_evaluation_artifacts=model_evaluation_artifacts)\n",
        "            logging.info(\"If model is accepted in model evaluation, pushing the model into production storage\")\n",
        "            model_pusher_artifacts = model_pusher.initiate_model_pusher()\n",
        "            logging.info(f\"Model pusher artifacts: is_model_pushed={model_pusher_artifacts.response['is_model_pushed']}, \"\n",
        "                        f\"s3_model_path={model_pusher_artifacts.response['s3_model_path']}\")\n",
        "            logging.info(\"Model pusher step completed successfully in train pipeline\")\n",
        "            return model_pusher_artifacts\n",
        "        except Exception as e:\n",
        "            raise CustomException(e, sys)\n",
        "\n",
        "    def run_pipeline(self) -> None:\n",
        "        logging.info(\">>>> Initializing training pipeline <<<<\")\n",
        "        try:\n",
        "            data_ingestion_artifacts = self.start_data_ingestion()\n",
        "            data_transformation_artifact = self.start_data_transformation(data_ingestion_artifacts=data_ingestion_artifacts)\n",
        "            model_trainer_artifact = self.start_model_trainer(data_transformation_artifact=data_transformation_artifact)\n",
        "            model_evaluation_artifacts = self.start_model_evaluation(data_transformation_artifact, model_trainer_artifact)\n",
        "            model_pusher_artifact = self.start_model_pusher(model_evaluation_artifacts=model_evaluation_artifacts)\n",
        "            logging.info(f\"Pipeline completed! Model pusher artifact: is_model_pushed={model_pusher_artifact.response['is_model_pushed']}, \"\n",
        "                        f\"s3_model_path={model_pusher_artifact.response['s3_model_path']}\")\n",
        "            print(model_pusher_artifact)\n",
        "        except Exception as e:\n",
        "            raise CustomException(e, sys)"
      ],
      "metadata": {
        "id": "iMUN1y74cCuK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}